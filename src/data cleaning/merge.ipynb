{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.0-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37064bitcapstoneconda4c011bf3812e465f9a235200dba099ea",
   "display_name": "Python 3.7.0 64-bit ('Capstone': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(env, maple):\n",
    "    env_df = pd.read_csv(env).copy()\n",
    "    maple_df = pd.read_csv(maple).copy()\n",
    "\n",
    "    maple_df.drop(\"STATE\", axis=1, inplace=True)\n",
    "    env_df.rename(columns={\"DATE\": \"YEAR\"}, inplace=True)\n",
    "\n",
    "    cols_to_add = set(list(maple_df.columns) + list(env_df.columns))\n",
    "    df = pd.DataFrame(columns=cols_to_add)\n",
    "\n",
    "    return env_df, maple_df, df\n",
    "\n",
    "def merge_data(env, maple, merged):\n",
    "    # group each dataframe by county and year\n",
    "    maple_groupby = maple.groupby([\"COUNTY\", \"YEAR\"])\n",
    "    env_groupby = env.groupby([\"COUNTY\", \"YEAR\"])\n",
    "\n",
    "    # loop through all the counties\n",
    "    for county in maple[\"COUNTY\"].unique():\n",
    "        # get the county data\n",
    "        county_data = maple[maple[\"COUNTY\"] == county]\n",
    "        for year in county_data[\"YEAR\"].unique():\n",
    "            # check if there's env data for that county and year\n",
    "            if county.capitalize() in env[\"COUNTY\"].unique() and year in env[\"YEAR\"].unique():\n",
    "                # get the related environmental data\n",
    "                env_group = env_groupby.get_group((county.capitalize(), year))\n",
    "                # get the correct maple syrup data\n",
    "                maple_group = maple_groupby.get_group((county, year))\n",
    "\n",
    "                # construct the merged row\n",
    "                new_row = dict()\n",
    "                for col in env.columns:\n",
    "                    new_row[col] = env_group[col].values[0]\n",
    "                for col in maple.columns:\n",
    "                    new_row[col] = maple_group[col].values[0]\n",
    "\n",
    "                # add to the merged dataframe\n",
    "                merged = merged.append(new_row, ignore_index=True)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "def reorder_columns(df):\n",
    "    cols = ['YEAR', 'COUNTY', 'OPERATIONS WITH TAPS', 'OPERATIONS WITH SALES', 'NUMBER OF TAPS', 'SALES', 'PRODUCTION', 'TAVG', 'FZF9', 'HTDD', 'DX32', 'FZF5', 'EMXP', 'SNOW', 'TMIN', 'DX70', 'FZF0', 'EMNT', 'FZF4', 'FZF6', 'FZF2', 'DX90', 'EMXT', 'CDSD', 'PRCP', 'FZF7', 'TMAX', 'FZF8', 'DT32', 'DT00', 'CLDD', 'FZF3', 'FZF1']\n",
    "    df = df[cols]\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_data = \"../../data/cleaned/environment/environment predictions.csv\"\n",
    "maple_data = \"../../data/cleaned/maple/cleaned county data.csv\"\n",
    "\n",
    "merged_data = merge_data(*load_data(env_data, maple_data))\n",
    "merged_data = reorder_columns(merged_data)\n",
    "\n",
    "merged_data.to_csv(\"../../data/cleaned/merged data.csv\", index=False)"
   ]
  }
 ]
}